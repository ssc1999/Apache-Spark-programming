{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5836ed8d-0af4-45b3-b5ed-2a4d33e90ec5"}}},{"cell_type":"markdown","source":["# Explore Datasets Lab\n\nWe will use tools introduced in this lesson to explore the datasets used in this course.\n\n### BedBricks Case Study\nThis course uses a case study that explores clickstream data for the online mattress retailer, BedBricks.  \nYou are an analyst at BedBricks working with the following datasets: **`events`**, **`sales`**, **`users`**, and **`products`**.\n\n##### Tasks\n1. View data files in DBFS using magic commands\n1. View data files in DBFS using dbutils\n1. Create tables from files in DBFS\n1. Execute SQL to answer questions on BedBricks datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0569026-8dba-4b1a-9e7a-cc9ca799f8dc"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"626d61a0-604d-4267-8827-34a2802a46aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Resetting the learning environment...\n...dropping the database \"da_sergio_salgado_4613_asp\"...(3 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks\"...(0 seconds)\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\nValidating the locally installed datasets...(3 seconds)\n\nPredefined tables in \"da_sergio_salgado_4613_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks/database.db\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 9 seconds\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Resetting the learning environment...\n...dropping the database \"da_sergio_salgado_4613_asp\"...(3 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks\"...(0 seconds)\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\nValidating the locally installed datasets...(3 seconds)\n\nPredefined tables in \"da_sergio_salgado_4613_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks/database.db\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/sergio.salgado@n.world/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 9 seconds\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1. List data files in DBFS using magic commands\nUse a magic command to display files located in the DBFS directory: **`dbfs:/user`**\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see several user directories including your own. Depending on your permissions, you may see only your user directory."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88d089bf-8950-427f-8c1d-46f2ca6930de"}}},{"cell_type":"code","source":["# TODO\ndbutils.fs.ls(\"dbfs:/user\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0060f996-d9a2-4ae6-9f0e-0badae964e1f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[12]: [FileInfo(path='dbfs:/user/hive/', name='hive/', size=0, modificationTime=0)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: [FileInfo(path='dbfs:/user/hive/', name='hive/', size=0, modificationTime=0)]"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. List data files in DBFS using dbutils\n- Use **`dbutils`** to get the files at the directory above and assign it to the variable **`files`**\n- Use the Databricks display() function to display the contents in **`files`**\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Just as before, you should see several user directories including your own."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8e5b3c4-4a54-4b6b-a3f8-97405512851f"}}},{"cell_type":"code","source":["# TODO\nfiles = dbutils.fs.ls(\"dbfs:/user\")\ndisplay(files)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d766c22b-4991-4894-b67c-ff918fa9281b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/user/hive/","hive/",0,0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/</td><td>hive/</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Create tables below from files in DBFS\n- Create the **`users`** table using the spark-context variable **`DA.paths.users`**\n- Create the **`sales`** table using the spark-context variable **`DA.paths.sales`**\n- Create the **`products`** table using the spark-context variable **`DA.paths.products`**\n- Create the **`events`** table using the spark-context variable **`DA.paths.events`**\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\"> Hint: We created the **`events`** table in the previous notebook but in a different database."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21739b69-cc2f-48fb-b9fa-bee700a09fdc"}}},{"cell_type":"code","source":["%sql\nCREATE TABLE IF NOT EXISTS users\nUSING DELTA\nOPTIONS (path = \"${DA.paths.users}\");\n\nCREATE TABLE IF NOT EXISTS sales\nUSING DELTA\nOPTIONS (path = \"${DA.paths.sales}\");\n\nCREATE TABLE IF NOT EXISTS products\nUSING DELTA\nOPTIONS (path = \"${DA.paths.products}\");\n\nCREATE TABLE IF NOT EXISTS events\nUSING DELTA\nOPTIONS (path = \"${DA.paths.events}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0a63f280-5e0b-408a-903b-ea44d3442865"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Use the data tab of the workspace UI to confirm your tables were created."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e14d2ea-9890-454f-8cad-eb9623fcb0ec"}}},{"cell_type":"markdown","source":["### 4. Execute SQL to explore BedBricks datasets\nRun SQL queries on the **`products`**, **`sales`**, and **`events`** tables to answer the following questions. \n- What products are available for purchase at BedBricks?\n- What is the average purchase revenue for a transaction at BedBricks?\n- What types of events are recorded on the BedBricks website?\n\nThe schema of the relevant dataset is provided for each question in the cells below."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bced584c-b8f3-4e5f-ad4e-5c55c37d97ed"}}},{"cell_type":"markdown","source":["#### 4.1: What products are available for purchase at BedBricks?\n\nThe **`products`** dataset contains the ID, name, and price of products on the BedBricks retail site.\n\n| field | type | description\n| --- | --- | --- |\n| item_id | string | unique item identifier |\n| name | string | item name in plain text |\n| price | double | price of item |\n\nExecute a SQL query that selects all from the **`products`** table. \n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see 12 products."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e09bc3b9-8caa-4f32-9974-5159ce2998b9"}}},{"cell_type":"code","source":["%sql\n SELECT * FROM products"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"064bf924-54c4-4602-bb90-9665c75b2fea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["M_PREM_Q","Premium Queen Mattress",1795.0],["M_STAN_F","Standard Full Mattress",945.0],["M_PREM_F","Premium Full Mattress",1695.0],["M_PREM_T","Premium Twin Mattress",1095.0],["M_PREM_K","Premium King Mattress",1995.0],["P_DOWN_S","Standard Down Pillow",119.0],["M_STAN_Q","Standard Queen Mattress",1045.0],["M_STAN_K","Standard King Mattress",1195.0],["M_STAN_T","Standard Twin Mattress",595.0],["P_FOAM_S","Standard Foam Pillow",59.0],["P_FOAM_K","King Foam Pillow",79.0],["P_DOWN_K","King Down Pillow",159.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"item_id","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"price","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>item_id</th><th>name</th><th>price</th></tr></thead><tbody><tr><td>M_PREM_Q</td><td>Premium Queen Mattress</td><td>1795.0</td></tr><tr><td>M_STAN_F</td><td>Standard Full Mattress</td><td>945.0</td></tr><tr><td>M_PREM_F</td><td>Premium Full Mattress</td><td>1695.0</td></tr><tr><td>M_PREM_T</td><td>Premium Twin Mattress</td><td>1095.0</td></tr><tr><td>M_PREM_K</td><td>Premium King Mattress</td><td>1995.0</td></tr><tr><td>P_DOWN_S</td><td>Standard Down Pillow</td><td>119.0</td></tr><tr><td>M_STAN_Q</td><td>Standard Queen Mattress</td><td>1045.0</td></tr><tr><td>M_STAN_K</td><td>Standard King Mattress</td><td>1195.0</td></tr><tr><td>M_STAN_T</td><td>Standard Twin Mattress</td><td>595.0</td></tr><tr><td>P_FOAM_S</td><td>Standard Foam Pillow</td><td>59.0</td></tr><tr><td>P_FOAM_K</td><td>King Foam Pillow</td><td>79.0</td></tr><tr><td>P_DOWN_K</td><td>King Down Pillow</td><td>159.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 4.2: What is the average purchase revenue for a transaction at BedBricks?\n\nThe **`sales`** dataset contains order information representing successfully processed sales.  \nMost fields correspond directly with fields from the clickstream data associated with a sale finalization event.\n\n| field | type | description|\n| --- | --- | --- |\n| order_id | long | unique identifier |\n| email | string | the email address to which sales configuration was sent |\n| transaction_timestamp | long | timestamp at which the order was processed, recorded in milliseconds since epoch |\n| total_item_quantity | long | number of individual items in the order |\n| purchase_revenue_in_usd | double | total revenue from order |\n| unique_items | long | number of unique products in the order |\n| items | array | provided as a list of JSON data, which is interpreted by Spark as an array of structs |\n\nExecute a SQL query that computes the average **`purchase_revenue_in_usd`** from the **`sales`** table.\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> The result should be **`1042.79`**."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6219d0c-a52e-4e91-bde3-ef071611e7f3"}}},{"cell_type":"code","source":["%sql\nSELECT AVG(purchase_revenue_in_usd)AS average_revenue_in_usd FROM sales"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"158f6a90-07bf-4da5-baad-5dc35d4f43fa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1042.7902657223433]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"average_revenue_in_usd","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>average_revenue_in_usd</th></tr></thead><tbody><tr><td>1042.7902657223433</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 4.3: What types of events are recorded on the BedBricks website?\n\nThe **`events`** dataset contains two weeks worth of parsed JSON records, created by consuming updates to an operational database.  \nRecords are received whenever: (1) a new user visits the site, (2) a user provides their email for the first time.\n\n| field | type | description|\n| --- | --- | --- |\n| device | string | operating system of the user device |\n| user_id | string | unique identifier for user/session |\n| user_first_touch_timestamp | long | first time the user was seen in microseconds since epoch |\n| traffic_source | string | referral source |\n| geo (city, state) | struct | city and state information derived from IP address |\n| event_timestamp | long | event time recorded as microseconds since epoch |\n| event_previous_timestamp | long | time of previous event in microseconds since epoch |\n| event_name | string | name of events as registered in clickstream tracker |\n| items (item_id, item_name, price_in_usd, quantity, item_revenue in usd, coupon)| array | an array of structs for each unique item in the userâ€™s cart |\n| ecommerce (total_item_quantity, unique_items, purchase_revenue_in_usd)  |  struct  | purchase data (this field is only non-null in those events that correspond to a sales finalization) |\n\nExecute a SQL query that selects distinct values in **`event_name`** from the **`events`** table\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> You should see 23 distinct **`event_name`** values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"423296ca-c009-4d79-a36b-4551c344158e"}}},{"cell_type":"code","source":["%sql\nSELECT DISTINCT event_name FROM events"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6399a57e-9301-4480-ae53-9069a75df2c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["mattresses"],["down"],["press"],["shipping_info"],["main"],["warranty"],["finalize"],["login"],["faq"],["careers"],["pillows"],["original"],["cart"],["delivery"],["cc_info"],["guest"],["add_item"],["email_coupon"],["premium"],["register"],["checkout"],["reviews"],["foam"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"event_name","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>event_name</th></tr></thead><tbody><tr><td>mattresses</td></tr><tr><td>down</td></tr><tr><td>press</td></tr><tr><td>shipping_info</td></tr><tr><td>main</td></tr><tr><td>warranty</td></tr><tr><td>finalize</td></tr><tr><td>login</td></tr><tr><td>faq</td></tr><tr><td>careers</td></tr><tr><td>pillows</td></tr><tr><td>original</td></tr><tr><td>cart</td></tr><tr><td>delivery</td></tr><tr><td>cc_info</td></tr><tr><td>guest</td></tr><tr><td>add_item</td></tr><tr><td>email_coupon</td></tr><tr><td>premium</td></tr><tr><td>register</td></tr><tr><td>checkout</td></tr><tr><td>reviews</td></tr><tr><td>foam</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5cfafea-3253-4d9d-b304-ed0769fd39fb"}}},{"cell_type":"code","source":["DA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e51f6d2c-eb24-4d4b-b30c-db9c84f23628"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab9ce7bd-4f0c-4baf-8412-2e4c07475d40"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 1.1L - Explore Datasets Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3111103097068019}},"nbformat":4,"nbformat_minor":0}
